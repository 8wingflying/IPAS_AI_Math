# KL Divergenceï¼ˆKullbackâ€“Leibler Divergenceï¼‰

---

## ğŸ“˜ 1. ä»€éº¼æ˜¯ KL Divergenceï¼Ÿ

**KL æ•£åº¦ï¼ˆKullbackâ€“Leibler Divergenceï¼‰** æ˜¯ç”¨ä¾†è¡¡é‡å…©å€‹æ©Ÿç‡åˆ†å¸ƒ  
**Pï¼ˆçœŸå¯¦åˆ†å¸ƒï¼‰** èˆ‡ **Qï¼ˆè¿‘ä¼¼åˆ†å¸ƒï¼‰** ä¹‹é–“å·®ç•°çš„ã€Œä¸å°ç¨±è·é›¢ã€ã€‚

å®ƒè¡¡é‡ï¼š  
> ä½¿ç”¨ Q è¿‘ä¼¼ P æ™‚ï¼Œæå¤±äº†å¤šå°‘è³‡è¨Šï¼ˆinformation lossï¼‰

---

# ğŸ“ 2. KL Divergence å®šç¾©å…¬å¼

## ğŸ“Œ é›¢æ•£åˆ†å¸ƒ

$$
D_{KL}(P \| Q)=\sum_x P(x)\log\frac{P(x)}{Q(x)}
$$

---

## ğŸ“Œ é€£çºŒåˆ†å¸ƒ

$$
D_{KL}(P \| Q)=\int_{-\infty}^{\infty} p(x)\log\frac{p(x)}{q(x)} dx
$$

---

# ğŸ” 3. KL Divergence çš„æ€§è³ª

| æ€§è³ª | èªªæ˜ |
|------|------|
| éè² æ€§ | $D_{KL}(P\|Q) \ge 0$ï¼ˆGibbsä¸ç­‰å¼ï¼‰ |
| ä¸å°ç¨± | $D_{KL}(P\|Q) \ne D_{KL}(Q\|P)$ |
| ä¸æ˜¯çœŸæ­£çš„è·é›¢ | å› ç‚ºä¸å°ç¨±ã€ä¹Ÿä¸æ»¿è¶³ä¸‰è§’ä¸ç­‰å¼ |
| 0 ä»£è¡¨åˆ†å¸ƒå®Œå…¨ç›¸åŒ | $P=Q$ æ™‚ KL=0 |

---

# ğŸ“Š 4. å¸¸è¦‹ä¾‹å­ï¼šå…©å€‹å¸¸æ…‹åˆ†å¸ƒçš„ KL Divergence

è‹¥

$$
P = \mathcal{N}(\mu_1,\sigma_1^2), \quad 
Q = \mathcal{N}(\mu_2,\sigma_2^2)
$$

å‰‡

$$
D_{KL}(P\|Q)=
\log\frac{\sigma_2}{\sigma_1}
+ \frac{\sigma_1^2 + (\mu_1-\mu_2)^2}{2\sigma_2^2}
-\frac{1}{2}
$$

---

# ğŸ§ª 5. SymPy è¨ˆç®— KL Divergenceï¼ˆé›¢æ•£ï¼‰

```python
import sympy as sp

# å®šç¾©é›¢æ•£æ©Ÿç‡
p1, p2 = sp.Rational(1,2), sp.Rational(1,2)
q1, q2 = sp.Rational(1,4), sp.Rational(3,4)

# KL divergence
KL = p1*sp.log(p1/q1) + p2*sp.log(p2/q2)
KL.simplify()
ğŸ§ª 6. SymPy è¨ˆç®— KL Divergenceï¼ˆé€£çºŒ Normalï¼‰
python
æ°¸é é¡¯ç¤ºè©³ç´°è³‡æ–™

è¤‡è£½ç¨‹å¼ç¢¼
import sympy as sp

mu1, mu2 = sp.symbols('mu1 mu2', real=True)
s1, s2 = sp.symbols('s1 s2', positive=True)

KL = sp.log(s2/s1) + (s1**2 + (mu1-mu2)**2)/(2*s2**2) - sp.Rational(1,2)
sp.simplify(KL)
